================================================================================
                    LLM 알파 생성 파이프라인 - 결과 판독 가이드
================================================================================

- 목적: 시뮬레이션 결과(results/*.csv)를 빠르게 분석하고 제출 가능한 알파를 선별

================================================================================
빠른 사용법 (3단계)
================================================================================

1) 파일 열기
   - results/USA_TOP3000_{category}.csv 파일을 Excel 또는 pandas로 열기
   - 예: results/USA_TOP3000_risk.csv

2) 핵심 컬럼 확인
   - id                    : 알파 ID (None이면 시뮬 실패)
   - is-sharpe             : Sharpe Ratio (>=1.58 필수)
   - is-fitness            : Fitness (>=1.0 필수)
   - is-checks-0-result    : LOW_SHARPE 체크 (PASS 필수)

3) 탈락/통과 기준
   - 탈락: id가 None 또는 is-checks-*-result 중 하나라도 FAIL
   - 통과: 모든 checks가 PASS이고 is-sharpe >= 1.58, is-fitness >= 1.0

================================================================================
결과 읽는 순서
================================================================================

[1단계] 시뮬레이션 성공 여부 판단
------------------------------------------------------------------------
   - 컬럼: id
   - 성공: 알파 ID 존재 (예: "rKQWRbQ3")
   - 실패: None, 빈값, 또는 컬럼 자체가 없음
   - 실패 원인: Sanity 통과했지만 Brain에서 오류 (데이터필드 미지원, syntax 오류 등)

[2단계] In-Sample(IS) 핵심 지표 해석
------------------------------------------------------------------------
   컬럼명          | 의미                | 좋은 값      | 나쁜 값
   ----------------|---------------------|--------------|----------
   is-sharpe       | 위험 대비 수익      | >= 2.0       | < 1.58
   is-fitness      | 종합 적합도         | >= 1.5       | < 1.0
   is-turnover     | 일평균 회전율       | 0.1 ~ 0.5    | < 0.01 또는 > 0.7
   is-returns      | 총 수익률           | 양수         | 음수
   is-drawdown     | 최대 낙폭           | > -0.1       | < -0.2
   is-margin       | 마진                | > 0          | <= 0

[3단계] Train/Test 안정성 체크
------------------------------------------------------------------------
   - train-sharpe vs is-sharpe: 큰 차이 없어야 함
   - test-sharpe (있는 경우): IS와 비슷한 수준이어야 안정적
   - 주의: train에서만 좋고 test에서 급락하면 오버피팅 의심

[4단계] Checks (제출 관련 테스트) 해석
------------------------------------------------------------------------
   컬럼명                   | 의미                    | 통과 조건
   -------------------------|-------------------------|----------------
   is-checks-0-result       | LOW_SHARPE              | Sharpe >= 1.58
   is-checks-1-result       | LOW_FITNESS             | Fitness >= 1.0
   is-checks-2-result       | LOW_TURNOVER            | Turnover >= 0.01
   is-checks-3-result       | HIGH_TURNOVER           | Turnover <= 0.7
   is-checks-4-result       | CONCENTRATED_WEIGHT     | 집중도 기준 충족
   is-checks-5-result       | LOW_SUB_UNIVERSE_SHARPE | 하위 유니버스 성과

   * 모든 항목이 PASS여야 제출 가능
   * PENDING: 아직 계산 중 (기다리거나 재조회 필요)
   * WARNING: 주의 필요하지만 제출은 가능

[5단계] 중복/상관 체크
------------------------------------------------------------------------
   - SELF_CORRELATION: 내가 이전에 제출한 알파와의 상관관계
     -> 0.7 미만이어야 제출 가능
     -> CSV에 직접 없음, ace_lib.check_self_corr_test() 별도 호출 필요

   - PROD_CORRELATION: 프로덕션 알파와의 상관관계
     -> 0.7 이하여야 제출 가능
     -> CSV에 직접 없음, ace_lib.check_prod_corr_test() 별도 호출 필요

================================================================================
자주 나오는 실패 케이스 & 대처
================================================================================

[케이스 1] Sanity 통과했는데 시뮬 실패 (id = None)
------------------------------------------------------------------------
   원인:
   - 데이터필드가 해당 region/universe에서 지원되지 않음
   - Expression 문법 오류 (Sanity는 타입만 체크)
   - 데이터 coverage 부족

   대처:
   - gen_json에서 해당 implementation 확인
   - 데이터필드 ID가 올바른지 ace.get_datafields()로 재확인
   - 다른 데이터필드로 대체

[케이스 2] 모든 Check PASS인데 성과가 별로인 경우
------------------------------------------------------------------------
   원인:
   - Sharpe 1.58은 최소 기준일 뿐, 좋은 알파 기준이 아님
   - LLM이 생성한 아이디어가 실제로는 약한 시그널

   대처:
   - is-fitness >= 1.5, is-sharpe >= 2.0 기준으로 재필터
   - confidence_level 높은 알파 우선 검토
   - implementation 로직이 합리적인지 사람이 검토

[케이스 3] Turnover가 과도한 경우 (> 0.7)
------------------------------------------------------------------------
   원인:
   - ts_zscore 윈도우가 너무 짧음 (예: 3일)
   - 노이즈에 민감한 데이터필드 사용

   대처:
   - decay 파라미터 추가 (예: decay=5)
   - ts_* 연산자 윈도우 늘리기
   - 해당 알파 스킵

[케이스 4] Turnover가 너무 낮은 경우 (< 0.01)
------------------------------------------------------------------------
   원인:
   - 거의 변하지 않는 데이터필드 사용
   - 결과가 사실상 상수

   대처:
   - implementation이 subtract(x, x) 같은 형태가 아닌지 확인
   - 해당 알파 스킵

[케이스 5] 특정 데이터셋에서만 성과가 나오는 경우
------------------------------------------------------------------------
   원인:
   - 해당 데이터셋의 특성에 오버피팅
   - 특정 섹터/기간에만 유효한 시그널

   대처:
   - 다른 region (EUR, ASI)에서도 테스트
   - 다른 기간으로 IS/OOS 분할 테스트
   - 해당 아이디어를 다른 유사 데이터셋에 적용해보기

================================================================================
추천 최소 기준 (예시)
================================================================================

※ 아래 수치는 예시이며, 실제 기준은 사용자/대회 규정에 맞게 조정하세요.

[제출 필수 기준]
   - 모든 is-checks-*-result = PASS
   - is-sharpe >= 1.58
   - is-fitness >= 1.0
   - 0.01 <= is-turnover <= 0.7

[권장 기준 (1순위 검토 대상)]
   - is-fitness >= 1.5
   - is-sharpe >= 2.0
   - 0.1 <= is-turnover <= 0.5
   - is-drawdown > -0.15
   - confidence_level >= 0.65

[추가 검토 기준]
   - SELF_CORRELATION < 0.5 (중복 방지)
   - PROD_CORRELATION < 0.6 (차별화)
   - operator 개수 <= 5 (단순한 알파 선호)
   - datafield 개수 = 2 (조합의 힘)

================================================================================
빠른 필터링 Python 코드 예시
================================================================================

import pandas as pd

df = pd.read_csv('results/USA_TOP3000_risk.csv')

# 1) 시뮬 성공한 것만
df = df[df['id'].notna()]

# 2) 모든 체크 PASS
for i in range(6):
    col = f'is-checks-{i}-result'
    if col in df.columns:
        df = df[df[col] == 'PASS']

# 3) fitness/sharpe 정렬
df = df.sort_values(['is-fitness', 'is-sharpe'], ascending=False)

# 4) 상위 20개 검토
print(df[['id', 'regular-code', 'is-sharpe', 'is-fitness', 'is-turnover']].head(20))

================================================================================
문의/참고
================================================================================

- 노트북: llm_alpha_guide.ipynb
- 핵심 코드: llm_functions.py, parser.py, ace_lib.py
- Brain 플랫폼: https://platform.worldquantbrain.com
- 알파 상세 확인: https://platform.worldquantbrain.com/alpha/{alpha_id}

================================================================================
